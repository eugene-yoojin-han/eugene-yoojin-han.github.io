<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
	<head>
		<style>
			body {
				padding: 100px;
				width: 1000px;
				margin: auto;
				text-align: left;
				font-weight: 300;
				font-family: 'Open Sans', sans-serif;
				color: #121212;
			}
			h1, h2, h3, h4 {
				font-family: 'Source Sans Pro', sans-serif;
			}
			.rotate {
				transform: rotate(90deg);
			}
		</style>
		<title>CS 180 Project 5</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<link
			href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro"
			rel="stylesheet">
	</head>

	<body>

		<h1 align="middle">CS 180 Fall 2024</h1>
		<h1 align="middle">Project 5</h1>
		<h2 align="middle">Eugene Han</h2>
		<h2 align="middle">SID: 3036560489</h2>

		<br><br>

		<div>
			<h1 align="middle">Part B: Building Diffusion Models</h1>
			<h2 align="middle">Overview</h2>
			<p align="middle">This part of the project focuses on implementing diffusion models from scratch using the MNIST dataset. 
				We first build a single-step denoising UNet model that learns to map noisy images back to their clean versions. 
				Then we implement a full Denoising Diffusion Probabilistic Model that performs iterative denoising through multiple timesteps. 
				To control the generation process, we implement time conditioning and class conditioning while using the UNet architecture as the backbone. </p>
			<h2 align="middle">Part 1</h2>
			<p align="middle">In Part 1, we build a single-step denoising model using a UNet architecture. 
				We start by implementing the UNet architecture with various convolutional and upsampling/downsampling blocks, then we train it to minimize the L2 loss between the denoised output and the original clean image. 
				The model is specifically trained on images with noise level σ = 0.5, and then we evaluate its performance on both this noise level and other noise levels for generality.
			</p>
			<img src="visualization.png" align="middle" width="800px" />
			<p align="middle"> The image above is a visualization of the noising process in the process of training the denoiser that maps a noisy image to a clear iamge.</p>
			<br>
			<img src="loss.png" align="middle" width="800px" caption="training loss curve."/>
			<p align="middle"> Training loss curve of the denoiser.</p>
			<br>
			<img src="1stand5th.png" align="middle" width="800px" />
			<p align="middle"> Sample results on the test set after the first and the 5-th epoch. </p>
			<br>
			<img src="outofdistribution.png" align="middle" width="800px" />
			<p align="middle"> Sample results on the test set with out-of-distribution noise levels after the model is trained. </p>
			<br>
			<h2 align="middle">Part 2</h2>
			<p align="middle">In Part 2, we implement a full diffusion model (DDPM) that gradually denoises images over multiple timesteps.
				 Instead of trying to remove all noise at once, this model learns to predict and remove noise iteratively. 
				 The UNet is modified to include time conditioning, allowing it to know which step of the denoising process it's performing. 
				 The model is also trained using a variance schedule (β) that controls how noise is added and removed at each timestep. 
				 We also add class conditioning, which allows the model to generate specific MNIST digits by conditioning the generation process on the desired digit class. </p>			<img src="classloss.png" align="middle" width="800px" />
			<p align="middle"> Training loss curve of the class-conditioned denoiser. </p>
			<br>
			<table>
				<tr>
					<td>
						<img src="epoch5.png" align="middle" width="400px" />
					</td>
					
					<td>
						<img src="epoch20.png" align="middle" width="400px" />
					</td>
				</tr>
			</table>
			<p align="middle"> Sampling results for the class-conditioned UNet for 5 and 20 epochs. </p>
			
	</body>
</html>
